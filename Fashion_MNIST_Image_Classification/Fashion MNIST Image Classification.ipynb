{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Dataset - Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this notebook is available here: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "> Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label_map = {\n",
    "    't-shirt': 0,\n",
    "    'trouser': 1,\n",
    "    'pullover': 2,\n",
    "    'dress': 3,\n",
    "    'coat': 4,\n",
    "    'sandal': 5,\n",
    "    'shirt': 6,\n",
    "    'sneaker': 7,\n",
    "    'bag': 8,\n",
    "    'boot': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('data/fashion-mnist_test.csv')\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 19s 386us/sample - loss: 0.8430 - accuracy: 0.6854 - val_loss: 0.5092 - val_accuracy: 0.8020\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 19s 393us/sample - loss: 0.5245 - accuracy: 0.8025 - val_loss: 0.4265 - val_accuracy: 0.8468\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 19s 392us/sample - loss: 0.4576 - accuracy: 0.8309 - val_loss: 0.3776 - val_accuracy: 0.8644\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 19s 396us/sample - loss: 0.4139 - accuracy: 0.8470 - val_loss: 0.3515 - val_accuracy: 0.8685\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 19s 388us/sample - loss: 0.3794 - accuracy: 0.8602 - val_loss: 0.3277 - val_accuracy: 0.8794\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 18s 373us/sample - loss: 0.3573 - accuracy: 0.8683 - val_loss: 0.3033 - val_accuracy: 0.8863\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 18s 376us/sample - loss: 0.3383 - accuracy: 0.8763 - val_loss: 0.2947 - val_accuracy: 0.8929\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 18s 374us/sample - loss: 0.3247 - accuracy: 0.8805 - val_loss: 0.2896 - val_accuracy: 0.8923\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 18s 380us/sample - loss: 0.3111 - accuracy: 0.8860 - val_loss: 0.2752 - val_accuracy: 0.8995\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 18s 376us/sample - loss: 0.2991 - accuracy: 0.8888 - val_loss: 0.2775 - val_accuracy: 0.8962\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 18s 372us/sample - loss: 0.2952 - accuracy: 0.8908 - val_loss: 0.2597 - val_accuracy: 0.9035\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 18s 368us/sample - loss: 0.2857 - accuracy: 0.8935 - val_loss: 0.2606 - val_accuracy: 0.9029\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 18s 369us/sample - loss: 0.2764 - accuracy: 0.8997 - val_loss: 0.2520 - val_accuracy: 0.9061\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 18s 370us/sample - loss: 0.2708 - accuracy: 0.9003 - val_loss: 0.2511 - val_accuracy: 0.9048\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 18s 372us/sample - loss: 0.2662 - accuracy: 0.9024 - val_loss: 0.2487 - val_accuracy: 0.9090\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 18s 373us/sample - loss: 0.2631 - accuracy: 0.9033 - val_loss: 0.2435 - val_accuracy: 0.9091\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 18s 369us/sample - loss: 0.2574 - accuracy: 0.9049 - val_loss: 0.2405 - val_accuracy: 0.9090\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 18s 371us/sample - loss: 0.2509 - accuracy: 0.9059 - val_loss: 0.2372 - val_accuracy: 0.9117\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 20s 417us/sample - loss: 0.2488 - accuracy: 0.9069 - val_loss: 0.2374 - val_accuracy: 0.9100\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 23s 470us/sample - loss: 0.2466 - accuracy: 0.9070 - val_loss: 0.2387 - val_accuracy: 0.9096\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 23s 478us/sample - loss: 0.2443 - accuracy: 0.9099 - val_loss: 0.2334 - val_accuracy: 0.9126\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 23s 479us/sample - loss: 0.2386 - accuracy: 0.9112 - val_loss: 0.2419 - val_accuracy: 0.9086\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 23s 477us/sample - loss: 0.2319 - accuracy: 0.9125 - val_loss: 0.2292 - val_accuracy: 0.9137\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 23s 482us/sample - loss: 0.2304 - accuracy: 0.9132 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 23s 481us/sample - loss: 0.2275 - accuracy: 0.9149 - val_loss: 0.2306 - val_accuracy: 0.9146\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 23s 481us/sample - loss: 0.2271 - accuracy: 0.9146 - val_loss: 0.2280 - val_accuracy: 0.9157\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 23s 488us/sample - loss: 0.2256 - accuracy: 0.9172 - val_loss: 0.2289 - val_accuracy: 0.9149\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 20s 412us/sample - loss: 0.2228 - accuracy: 0.9156 - val_loss: 0.2270 - val_accuracy: 0.9160\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 21s 430us/sample - loss: 0.2172 - accuracy: 0.9170 - val_loss: 0.2225 - val_accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 20s 427us/sample - loss: 0.2170 - accuracy: 0.9179 - val_loss: 0.2232 - val_accuracy: 0.9164\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 18s 372us/sample - loss: 0.2124 - accuracy: 0.9211 - val_loss: 0.2233 - val_accuracy: 0.9159\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 17s 364us/sample - loss: 0.2154 - accuracy: 0.9203 - val_loss: 0.2217 - val_accuracy: 0.9164\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 18s 373us/sample - loss: 0.2067 - accuracy: 0.9220 - val_loss: 0.2276 - val_accuracy: 0.9158\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 18s 366us/sample - loss: 0.2090 - accuracy: 0.9221 - val_loss: 0.2280 - val_accuracy: 0.9169\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 18s 367us/sample - loss: 0.2061 - accuracy: 0.9234 - val_loss: 0.2216 - val_accuracy: 0.9190\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 18s 369us/sample - loss: 0.2044 - accuracy: 0.9214 - val_loss: 0.2218 - val_accuracy: 0.9196\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 18s 371us/sample - loss: 0.2000 - accuracy: 0.9253 - val_loss: 0.2250 - val_accuracy: 0.9151\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 18s 369us/sample - loss: 0.2018 - accuracy: 0.9246 - val_loss: 0.2221 - val_accuracy: 0.9182\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 18s 369us/sample - loss: 0.2011 - accuracy: 0.9237 - val_loss: 0.2168 - val_accuracy: 0.9202\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 18s 371us/sample - loss: 0.1988 - accuracy: 0.9250 - val_loss: 0.2218 - val_accuracy: 0.9170\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 18s 367us/sample - loss: 0.1957 - accuracy: 0.9266 - val_loss: 0.2227 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 18s 366us/sample - loss: 0.1948 - accuracy: 0.9258 - val_loss: 0.2196 - val_accuracy: 0.9187\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 18s 368us/sample - loss: 0.1962 - accuracy: 0.9259 - val_loss: 0.2218 - val_accuracy: 0.9193\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 20s 424us/sample - loss: 0.1916 - accuracy: 0.9273 - val_loss: 0.2217 - val_accuracy: 0.9206\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 20s 412us/sample - loss: 0.1897 - accuracy: 0.9280 - val_loss: 0.2163 - val_accuracy: 0.9210\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 18s 379us/sample - loss: 0.1887 - accuracy: 0.9288 - val_loss: 0.2177 - val_accuracy: 0.9198\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 20s 407us/sample - loss: 0.1882 - accuracy: 0.9280 - val_loss: 0.2162 - val_accuracy: 0.9202\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 18s 374us/sample - loss: 0.1884 - accuracy: 0.9294 - val_loss: 0.2145 - val_accuracy: 0.9214\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 18s 367us/sample - loss: 0.1890 - accuracy: 0.9290 - val_loss: 0.2161 - val_accuracy: 0.9207\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 18s 368us/sample - loss: 0.1845 - accuracy: 0.9305 - val_loss: 0.2184 - val_accuracy: 0.9212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ()",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
